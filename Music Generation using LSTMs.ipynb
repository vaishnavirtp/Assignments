{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41576fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting music21\n",
      "  Downloading music21-9.1.0-py3-none-any.whl (22.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.8/22.8 MB\u001b[0m \u001b[31m337.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting webcolors>=1.5\n",
      "  Downloading webcolors-1.13-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: requests in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from music21) (2.28.1)\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-9.1.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m531.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: chardet in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from music21) (4.0.0)\n",
      "Requirement already satisfied: joblib in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from music21) (1.1.1)\n",
      "Requirement already satisfied: numpy in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from music21) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from music21) (3.7.0)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m654.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m829.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from matplotlib->music21) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from matplotlib->music21) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from matplotlib->music21) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from matplotlib->music21) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from matplotlib->music21) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from matplotlib->music21) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from matplotlib->music21) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from matplotlib->music21) (22.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from requests->music21) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from requests->music21) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from requests->music21) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from requests->music21) (2023.5.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->music21) (1.16.0)\n",
      "Installing collected packages: webcolors, more-itertools, jsonpickle, music21\n",
      "Successfully installed jsonpickle-3.0.1 more-itertools-9.1.0 music21-9.1.0 webcolors-1.13\n"
     ]
    }
   ],
   "source": [
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81e9052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter,instrument,note,chord,stream\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6614dbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: ../Downloads/Classical/midi_songs/electric_de_chocobo.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Ff4-BattleLust.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/thenightmarebegins.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/dayafter.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Cids.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/thoughts.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/sandy.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/HighwindTakestotheSkies.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/traitor.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/balamb.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Life_Stream.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/path_of_repentance.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ff1battp.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ff4_piano_collections-main_theme.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ViviinAlexandria.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Zelda_Overworld.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Ff7-Cinco.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ff4-town.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/gerudo.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/0fithos.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/FF6epitaph_piano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/relmstheme-piano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ff8-lfp.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Ff7-Jenova_Absolute.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/tifap.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/EyesOnMePiano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Suteki_Da_Ne_(Piano_Version).mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ff6shap.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Still_Alive-1.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Kingdom_Hearts_Traverse_Town.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Rydia_pc.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/8.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/bcm.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/pkelite4.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ff4-airship.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaishnavi/anaconda3/lib/python3.10/site-packages/music21/midi/translate.py:874: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=6, channel=None, data=b'Pok\\xe9mon: Elite Four (Piano)'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: ../Downloads/Classical/midi_songs/cosmo.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Finalfantasy5gilgameshp.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/mining.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Final_Fantasy_Matouyas_Cave_Piano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Fierce_Battle_(Piano).mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/redwings.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/FFVII_BATTLE.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/sera_.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Gold_Silver_Rival_Battle.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ahead_on_our_way_piano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/z_aeristhemepiano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/sobf.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ff4pclov.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/figaro.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/lurk_in_dark.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Fyw_piano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ultros.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/FF8_Shuffle_or_boogie_pc.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ff7-mainmidi.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/rufus.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Ff7-One_Winged.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/In_Zanarkand.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ultimafro.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Finalfantasy6fanfarecomplete.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/tpirtsd-piano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/great_war.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/DOS.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/waltz_de_choco.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/FFIII_Edgar_And_Sabin_Piano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/JENOVA.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/OTD5YA.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/braska.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Kingdom_Hearts_Dearly_Beloved.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/FF3_Battle_(Piano).mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/FFIXQuMarshP.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ff7themep.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaishnavi/anaconda3/lib/python3.10/site-packages/music21/midi/translate.py:874: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Martin Rosok Copyright \\xa9 1998'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: ../Downloads/Classical/midi_songs/goldsaucer.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/dontbeafraid.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Eternal_Harvest.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Oppressed.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/FFIX_Piano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/fortresscondor.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/VincentPiano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ff4-fight1.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/costadsol.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/FF3_Third_Phase_Final_(Piano).mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Fiend_Battle_(Piano).mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/decisive.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/BlueStone_LastDungeon.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/AT.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/FF4.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/Rachel_Piano_tempofix.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/ff11_awakening_piano.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/caitsith.mid\n",
      "Loading Music File: ../Downloads/Classical/midi_songs/roseofmay-piano.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26557/3243476361.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  notes_array = np.array([read_midi(path+i) for i in files])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#specify the path\n",
    "path='../Downloads/Classical/midi_songs/'\n",
    "\n",
    "#read all the filenames\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94e777f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n"
     ]
    }
   ],
   "source": [
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6fc50a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([303.,  32.,  14.,  10.,   9.,   7.,   5.,   7.,   4.,   5.]),\n",
       " array([1.0000e+00, 1.4610e+02, 2.9120e+02, 4.3630e+02, 5.8140e+02,\n",
       "        7.2650e+02, 8.7160e+02, 1.0167e+03, 1.1618e+03, 1.3069e+03,\n",
       "        1.4520e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 428,
       "width": 443
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d93004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c27861d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26557/2871568428.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  new_music = np.array(new_music)\n"
     ]
    }
   ],
   "source": [
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7d051bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2caa6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "619c619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15bd9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f74c7efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3a61267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting jax>=0.3.15\n",
      "  Downloading jax-0.4.13.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: wrapt<1.15,>=1.11.0 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.3-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.24,>=1.22 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from tensorflow) (65.6.3)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting ml-dtypes>=0.1.0\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.7 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (1.10.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.2)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.28.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.21.0-py2.py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.1/182.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<2.0 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.14)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/vaishnavi/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hBuilding wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.13-py3-none-any.whl size=1518707 sha256=53dacf87d6dcf12684a0c46c70898b54c3ec98b82202a9a031e9b2496af0fe4e\n",
      "  Stored in directory: /home/vaishnavi/.cache/pip/wheels/4c/a3/e7/ea156aff3754a8f833f1b0c9587dec0bcfc9c551c439c9dcc7\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.21.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.56.0 jax-0.4.13 keras-2.12.0 libclang-16.0.0 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.3 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.3 tensorboard-data-server-0.7.1 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.32.0 termcolor-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d20c005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "      model = Sequential()\n",
    "      model.add(LSTM(128,return_sequences=True))\n",
    "      model.add(LSTM(128))\n",
    "      model.add(Dense(256))\n",
    "      model.add(Activation('relu'))\n",
    "      model.add(Dense(n_vocab))\n",
    "      model.add(Activation('softmax'))\n",
    "      model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f7519e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa28a3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 100)           13700     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 32, 64)            19264     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 8, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 256)            98560     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 4, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 256)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 137)               35209     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 257,229\n",
      "Trainable params: 257,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72f506fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3a28352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "327/330 [============================>.] - ETA: 0s - loss: 4.1539\n",
      "Epoch 1: val_loss improved from inf to 3.85722, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 4.1508 - val_loss: 3.8572\n",
      "Epoch 2/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 3.5986\n",
      "Epoch 2: val_loss improved from 3.85722 to 3.62229, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 3.5984 - val_loss: 3.6223\n",
      "Epoch 3/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 3.4078\n",
      "Epoch 3: val_loss improved from 3.62229 to 3.50156, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 3.4077 - val_loss: 3.5016\n",
      "Epoch 4/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 3.2871\n",
      "Epoch 4: val_loss improved from 3.50156 to 3.42257, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 3.2871 - val_loss: 3.4226\n",
      "Epoch 5/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 3.1963\n",
      "Epoch 5: val_loss improved from 3.42257 to 3.36948, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 3.1955 - val_loss: 3.3695\n",
      "Epoch 6/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 3.1171\n",
      "Epoch 6: val_loss improved from 3.36948 to 3.31042, saving model to best_model.h5\n",
      "330/330 [==============================] - 7s 22ms/step - loss: 3.1172 - val_loss: 3.3104\n",
      "Epoch 7/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 3.0476\n",
      "Epoch 7: val_loss improved from 3.31042 to 3.27721, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 3.0476 - val_loss: 3.2772\n",
      "Epoch 8/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.9886\n",
      "Epoch 8: val_loss improved from 3.27721 to 3.20517, saving model to best_model.h5\n",
      "330/330 [==============================] - 7s 22ms/step - loss: 2.9886 - val_loss: 3.2052\n",
      "Epoch 9/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 2.9300\n",
      "Epoch 9: val_loss improved from 3.20517 to 3.15778, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 2.9299 - val_loss: 3.1578\n",
      "Epoch 10/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.8784\n",
      "Epoch 10: val_loss improved from 3.15778 to 3.12383, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.8784 - val_loss: 3.1238\n",
      "Epoch 11/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.8266\n",
      "Epoch 11: val_loss improved from 3.12383 to 3.08106, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 2.8266 - val_loss: 3.0811\n",
      "Epoch 12/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 2.7858\n",
      "Epoch 12: val_loss improved from 3.08106 to 3.05505, saving model to best_model.h5\n",
      "330/330 [==============================] - 7s 22ms/step - loss: 2.7854 - val_loss: 3.0550\n",
      "Epoch 13/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.7439\n",
      "Epoch 13: val_loss improved from 3.05505 to 3.04112, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 2.7439 - val_loss: 3.0411\n",
      "Epoch 14/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.7075\n",
      "Epoch 14: val_loss improved from 3.04112 to 3.01263, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 2.7075 - val_loss: 3.0126\n",
      "Epoch 15/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 2.6684\n",
      "Epoch 15: val_loss improved from 3.01263 to 3.00626, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 2.6685 - val_loss: 3.0063\n",
      "Epoch 16/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.6406\n",
      "Epoch 16: val_loss improved from 3.00626 to 2.96915, saving model to best_model.h5\n",
      "330/330 [==============================] - 7s 22ms/step - loss: 2.6406 - val_loss: 2.9691\n",
      "Epoch 17/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.6115\n",
      "Epoch 17: val_loss improved from 2.96915 to 2.94955, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.6115 - val_loss: 2.9496\n",
      "Epoch 18/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.5810\n",
      "Epoch 18: val_loss improved from 2.94955 to 2.93617, saving model to best_model.h5\n",
      "330/330 [==============================] - 7s 22ms/step - loss: 2.5810 - val_loss: 2.9362\n",
      "Epoch 19/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.5459\n",
      "Epoch 19: val_loss improved from 2.93617 to 2.91858, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.5455 - val_loss: 2.9186\n",
      "Epoch 20/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.5210\n",
      "Epoch 20: val_loss improved from 2.91858 to 2.91105, saving model to best_model.h5\n",
      "330/330 [==============================] - 7s 22ms/step - loss: 2.5212 - val_loss: 2.9110\n",
      "Epoch 21/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.5009\n",
      "Epoch 21: val_loss improved from 2.91105 to 2.89385, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 25ms/step - loss: 2.5009 - val_loss: 2.8939\n",
      "Epoch 22/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 2.4724\n",
      "Epoch 22: val_loss improved from 2.89385 to 2.89234, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 2.4724 - val_loss: 2.8923\n",
      "Epoch 23/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.4543\n",
      "Epoch 23: val_loss improved from 2.89234 to 2.85475, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 2.4543 - val_loss: 2.8548\n",
      "Epoch 24/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 2.4324\n",
      "Epoch 24: val_loss did not improve from 2.85475\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.4322 - val_loss: 2.8602\n",
      "Epoch 25/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 2.4137\n",
      "Epoch 25: val_loss improved from 2.85475 to 2.84165, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.4138 - val_loss: 2.8416\n",
      "Epoch 26/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.3936\n",
      "Epoch 26: val_loss improved from 2.84165 to 2.83171, saving model to best_model.h5\n",
      "330/330 [==============================] - 7s 22ms/step - loss: 2.3940 - val_loss: 2.8317\n",
      "Epoch 27/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.3759\n",
      "Epoch 27: val_loss improved from 2.83171 to 2.83086, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 25ms/step - loss: 2.3759 - val_loss: 2.8309\n",
      "Epoch 28/50\n",
      "327/330 [============================>.] - ETA: 0s - loss: 2.3577\n",
      "Epoch 28: val_loss improved from 2.83086 to 2.81163, saving model to best_model.h5\n",
      "330/330 [==============================] - 7s 23ms/step - loss: 2.3586 - val_loss: 2.8116\n",
      "Epoch 29/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 2.3502\n",
      "Epoch 29: val_loss improved from 2.81163 to 2.80454, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.3499 - val_loss: 2.8045\n",
      "Epoch 30/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.3353\n",
      "Epoch 30: val_loss improved from 2.80454 to 2.78979, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.3351 - val_loss: 2.7898\n",
      "Epoch 31/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.3116\n",
      "Epoch 31: val_loss improved from 2.78979 to 2.77799, saving model to best_model.h5\n",
      "330/330 [==============================] - 7s 21ms/step - loss: 2.3117 - val_loss: 2.7780\n",
      "Epoch 32/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 2.2972\n",
      "Epoch 32: val_loss improved from 2.77799 to 2.77527, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 2.2967 - val_loss: 2.7753\n",
      "Epoch 33/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.2849\n",
      "Epoch 33: val_loss did not improve from 2.77527\n",
      "330/330 [==============================] - 7s 22ms/step - loss: 2.2851 - val_loss: 2.7798\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/330 [============================>.] - ETA: 0s - loss: 2.2801\n",
      "Epoch 34: val_loss improved from 2.77527 to 2.76846, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.2804 - val_loss: 2.7685\n",
      "Epoch 35/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 2.2634\n",
      "Epoch 35: val_loss improved from 2.76846 to 2.75943, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.2630 - val_loss: 2.7594\n",
      "Epoch 36/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.2495\n",
      "Epoch 36: val_loss improved from 2.75943 to 2.74721, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 25ms/step - loss: 2.2489 - val_loss: 2.7472\n",
      "Epoch 37/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 2.2431\n",
      "Epoch 37: val_loss improved from 2.74721 to 2.74126, saving model to best_model.h5\n",
      "330/330 [==============================] - 7s 22ms/step - loss: 2.2435 - val_loss: 2.7413\n",
      "Epoch 38/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.2281\n",
      "Epoch 38: val_loss did not improve from 2.74126\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 2.2281 - val_loss: 2.7532\n",
      "Epoch 39/50\n",
      "327/330 [============================>.] - ETA: 0s - loss: 2.2214\n",
      "Epoch 39: val_loss did not improve from 2.74126\n",
      "330/330 [==============================] - 7s 23ms/step - loss: 2.2217 - val_loss: 2.7426\n",
      "Epoch 40/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 2.2134\n",
      "Epoch 40: val_loss did not improve from 2.74126\n",
      "330/330 [==============================] - 8s 25ms/step - loss: 2.2131 - val_loss: 2.7467\n",
      "Epoch 41/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.2049\n",
      "Epoch 41: val_loss improved from 2.74126 to 2.73404, saving model to best_model.h5\n",
      "330/330 [==============================] - 7s 22ms/step - loss: 2.2050 - val_loss: 2.7340\n",
      "Epoch 42/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.1949\n",
      "Epoch 42: val_loss did not improve from 2.73404\n",
      "330/330 [==============================] - 8s 25ms/step - loss: 2.1948 - val_loss: 2.7444\n",
      "Epoch 43/50\n",
      "328/330 [============================>.] - ETA: 0s - loss: 2.1808\n",
      "Epoch 43: val_loss improved from 2.73404 to 2.72977, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.1814 - val_loss: 2.7298\n",
      "Epoch 44/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.1789\n",
      "Epoch 44: val_loss improved from 2.72977 to 2.72018, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.1787 - val_loss: 2.7202\n",
      "Epoch 45/50\n",
      "329/330 [============================>.] - ETA: 0s - loss: 2.1658\n",
      "Epoch 45: val_loss did not improve from 2.72018\n",
      "330/330 [==============================] - 7s 21ms/step - loss: 2.1660 - val_loss: 2.7238\n",
      "Epoch 46/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.1555\n",
      "Epoch 46: val_loss improved from 2.72018 to 2.71273, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 24ms/step - loss: 2.1555 - val_loss: 2.7127\n",
      "Epoch 47/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.1559\n",
      "Epoch 47: val_loss improved from 2.71273 to 2.71207, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.1559 - val_loss: 2.7121\n",
      "Epoch 48/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.1456\n",
      "Epoch 48: val_loss did not improve from 2.71207\n",
      "330/330 [==============================] - 8s 23ms/step - loss: 2.1456 - val_loss: 2.7223\n",
      "Epoch 49/50\n",
      "327/330 [============================>.] - ETA: 0s - loss: 2.1379\n",
      "Epoch 49: val_loss improved from 2.71207 to 2.70685, saving model to best_model.h5\n",
      "330/330 [==============================] - 7s 22ms/step - loss: 2.1382 - val_loss: 2.7069\n",
      "Epoch 50/50\n",
      "330/330 [==============================] - ETA: 0s - loss: 2.1283\n",
      "Epoch 50: val_loss improved from 2.70685 to 2.70507, saving model to best_model.h5\n",
      "330/330 [==============================] - 8s 25ms/step - loss: 2.1283 - val_loss: 2.7051\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9911dd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[55, 127, 125, 68, 125, 14, 68, 38, 14, 14]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(10):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "208aeec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1969b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music_new.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c76ee465",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff80f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
